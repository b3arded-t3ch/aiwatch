insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://www.reddit.com/r/MachineLearning/comments/5zgbyy/d_what_is_the_job_interview_process_like_at_openai/', /* url */
        '[D] What is the job interview process like at OpenAI?', /* title */
        '2017-03-14', /* publication_date */
        '2017-03-14', /* modified_date */
        'zergylord', /* author */
        'Reddit', /* publisher */
        'OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Job application experience', /* document_scope */
        'AI', /* cause_area */
        'The discussion thread includes descriptions of interview experiences by a few people, including one who went through the process but was rejected and one who went through the process, was accepted, but ultimately didn''t join. One reply suggests that open source contributions may help with landing an on-site interview' /* notes */
   )
  ,(
        'https://www.quora.com/What-was-your-experience-like-as-an-intern-at-OpenAI', /* url */
        'What was your experience like as an intern at OpenAI?', /* title */
        '2018-07-16', /* publication_date */
        '2018-07-19', /* modified_date */
        NULL, /* author */
        'Quora', /* publisher */
        'OpenAI', /* affected_organizations */
        'Kevin Frans', /* affected_people */
        'Job experience', /* document_scope */
        'AI', /* cause_area */
        'The question asks about people''s internship experience at OpenAI. There is one answer by Kevin Frans, who describes his internship experience from 2017. His first two weeks involved picking a project idea, after which his time was spent mainly on execution. He likes the open and friendly atmosphere, and the fact that people usually eat lunch together and can strike up conversations during lunch' /* notes */
   )
  ,(
        'https://www.reddit.com/r/MachineLearning/comments/63q056/d_what_do_interns_do_at_openai/', /* url */
        '[D] What do interns do at OpenAI?', /* title */
        '2017-04-05', /* publication_date */
        '2017-04-06', /* modified_date */
        'gsjbjt', /* author */
        'Reddit', /* publisher */
        'OpenAI', /* affected_organizations */
        'Ilya Sutskever', /* affected_people */
        'Job experience', /* document_scope */
        'AI', /* cause_area */
        'There is one substantive answer from Ilya Sutskever (Research Director), who says that interns have significant freedom, get to work closely with researchers, and that OpenAI generally hires non-PhD interns' /* notes */
   )
  ,(
        'https://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/', /* url */
        'AMA: the OpenAI Research Team', /* title */
        '2016-01-08', /* publication_date */
        '2016-01-09', /* modified_date */
        'Ilya Sutskever', /* author */
        'Reddit', /* publisher */
        'OpenAI', /* affected_organizations */
        'Ilya Sutskever|Andrej Karpathy|Durk Kingma|Greg Brockman|John Schulman|Vicki Cheung|Wojciech Zaremba', /* affected_people */
        'Job experience', /* document_scope */
        'AI', /* cause_area */
        '6 members of the OpenAI research team, including Research Director Ilya Sutskever, conduct an Ask Me Anything (AMA) on Reddit. This is about one month after the official launch of OpenAI' /* notes */
   )
  ,(
        'https://80000hours.org/podcast/episodes/the-world-needs-ai-researchers-heres-
	how-to-become-one/', /* url */
        'How to train for a job developing AI at OpenAI or DeepMind', /* title */
        '2017-07-21', /* publication_date */
        NULL, /* modified_date */
        'Robert Wiblin', /* author */
        '80,000 Hours', /* publisher */
        'OpenAI|DeepMind', /* affected_organizations */
        'Robert Wiblin|Daio Amodei', /* affected_people */
        'Job experience', /* document_scope */
        'AI', /* cause_area */
        'Robert Wiblin interviews Dario Amodei for the 80,000 Hours podcast about working at OpenAI and about the domains of AI and AI safety. The latter half of the podcast includes advice for people training to work in AI organizations such as OpenAI and DeepMind' /* notes */
   )
  ,(
        'https://www.lesswrong.com/posts/dJQo7xPn4TyGnKgeC/hiring-engineers-and-
	researchers-to-help-align-gpt-3', /* url */
        'Hiring engineers and researchers to help align GPT-3', /* title */
        '2020-10-01', /* publication_date */
        NULL, /* modified_date */
        'Paul Christiano', /* author */
        'LessWrong', /* publisher */
        'OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Paul Christiano posts on LessWrong a hiring note asking for engineers and researchers to work on GPT-3 alignment problems, as the language model is already being deployed in the OpenAI API' /* notes */
   )
,(
	'https://x.com/janleike/status/1352681093007200256', /* url */
	'Last week I joined OpenAI to lead their alignment effort.', /* title */
	'2021-01-22', /* publication_date */
	NULL, /* modified_date */
	'Jan Leike', /* author */
	'Twitter', /* publisher */
	'OpenAI', /* affected_organizations */
	'Jan Leike', /* affected_people */
	'Successful hire', /* document_scope */
	'AI Safety', /* cause_area */
	'In a tweet, Jan Leike announces joining OpenAI to lead the alignment effort. In comment, he states that his reason for joining OpenAI is that he loves OpenAI''s work on reward modeling and aligning GPT-3 using human preferences, and that he looks forward to building on it. However, in a 2024 tweet, Leike would reveal he joined OpenAI as he had thought it would be a better place to do research.' /* notes */
)
,(
	'https://openai.com/index/discovering-the-minutiae-of-backend-systems/', /* url */
	'Discovering the minutiae of backend systems', /* title */
	'2022-08-22', /* publication_date */
	NULL, /* modified_date */
	'OpenAI', /* author */
	'OpenAI', /* publisher */
	'OpenAI', /* affected_organizations */
	'Christian Gibson', /* affected_people */
	'Job experience', /* document_scope */
	'AI', /* cause_area */
	'This article contains an interview with Christian Gibson, an engineer on the supercomputing team of OpenAI, discussing how he got into programming as well as his work at OpenAI. In the interview, he discusses that his work focuses on solving problems that relate to Exploratory AI workflows by preempting research needs before they block progress and identifying bottlenecks as well as implementing workarounds as quickly as possible. Gibson''s account of working on supercomputing at OpenAI provides insights into the organization''s operations and culture. According to Gibson, OpenAI operates at an unprecedented scale, utilizing billion-dollar supercomputers and encountering technical challenges that push the boundaries of existing hardware capabilities. He mentions that the employees actively work to save days of compute time by relentlessly focusing on performance optimization to enable them match the cutting-edge technology. The work environment is characterized by a mix of coding, problem-solving, and collaboration, with employees having a clear understanding of how their work impacts specific teams and projects. According to him, employees also have the opportunity to tackle unique technical challenges in high-performance computing which contributes to employee motivation.' /* notes */
)
,(
	'https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-
	society-acknowledges/story?id=97897122', /* url */
	'OpenAI CEO Sam Altman says AI will reshape society,
	acknowledges risks: ''A little bit scared of this''', /* title */
	'2023-03-16', /* publication_date */
	NULL, /* modified_date */
	'Victor Ordonez|Taylor Dunn|Eric Noll', /* author */
	'abc NEWS', /* publisher */
	'OpenAI', /* affected_organizations */
	'Sam Altman', /* affected_people */
	'General discussion of organizational practices', /* document_scope */
	'AI Safety', /* cause_area */
	'A few months after the release of GPT-4, ABC News'' chief business, technology and economics correspondent Rebecca Jarvis interview Sam Altman about the rollout of GPT-4. In the interview, Sam Altman expresses his concerns about potential misuse of the AI technology; however, he maintains that OpenAI is in regular contact with government officials as the organization needs both regulators and society to prevent the potential negative consequences the technology could have on human.' /* notes */
)
,(
	'https://time.com/6288245/openai-eu-lobbying-ai-act/',  /* url */
	'Exclusive: OpenAI Lobbied the E.U. to Water Down AI Regulation',  /* title */
	'2023-06-20', /* publication_date */
	NULL, /* modified_date */
	'Billy Perrigo', /* author */
	'TIME', /* publisher */
	'OpenAI', /* affected_organizations */ 
	'Sam Altman', /* affected_people */
	'Third-party commentary on organization', /* document_scope */
	'AI Safety', /* cause_area */
	'The author of this article claims that OpenAI manages to influence the E.U.''s AI Act. He argues that although Sam Altman has been the major preacher for global AI regulation, he lobbies, behind the scenes, for certain elements of the legislation to be in the favour of OpenAI. According to him, "OpenAI’s lobbying effort appears to have been a success: the final draft of the Act approved by E.U. lawmakers did not contain wording present in earlier drafts suggesting that general purpose AI systems should be considered inherently high risk". Meanwhile, the author claims that "in 2022, OpenAI repeatedly argued to European officials that the forthcoming AI Act should not consider its general purpose AI systems—including GPT-3, the precursor to ChatGPT, and the image generator Dall-E 2—to be high risk,"' /* notes */
)
,(
	'https://openai.com/index/openai-announces-leadership-transition/', /* url */
        'OpenAI announces leadership transition', /* title */
        '2023-11-17', /* publication_date */
        NULL, /* modified_date */
        'OpenAI', /* author */
        'OpenAI', /* publisher */
        'OpenAI', /* affected_organizations */
        'Sam Altman', /* affected_people */
        'Employee departure', /* document_scope */
        'AI Safety', /* cause_area */
        'This article highlights the decision of the the board of directors of OpenAI to let relieve Sam Altman of his position as the CEO of the organization. According to them, his dismissal hinges on gaps in communications with the board which hinder its ability to exercise its responsibilities. However, a tweet mentions that Sam''s dismissal was sequel to some internal disagreements about safe development of AI.' /* notes */
)
,(
	'https://www.lesswrong.com/posts/eHFo7nwLYDzpuamRM/sam-altman-fired-from-
	openai#SYhfi45LhtX75Tr9v', /* url */
        'Hmmm. The way Sam behaves I can''t see a path of him leading an AI company towards safety', /* title */
        '2023-11-18', /* publication_date */
        NULL, /* modified_date */
        'MiguelDev', /* author */
        'LessWrong',  /* publisher */
        'OpenAI', /* affected_organizations */
        'Sam Altman', /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI Safety', /* cause_area */
	'MiguelDev, in a comment, describes what a typical CEO of OpenAI should be like. He says, "A CEO I wish OpenAI has - is someone who stays at the offices, ensuring that we are on track of safely steering arguably the most revolutionary tech ever created - not trying to promote the company or the tech, I think it''s unnecessary to do a world tour if one is doing AI development and deployment safely."' /* notes */
)
,(
	'https://www.lesswrong.com/posts/gZkYvA6suQJthvj4E/my-may-2023-priorities-for-
	ai-x-safety-more-empathy-more4', /* url */
	'My May 2023 priorities for AI x-safety: more empathy,
	more unification of concerns, and less vilification of OpenAI', /* title */
        '2023-05-24', /* publication_date */
	NULL, /* modified_date */
	'Andrew_Critch', /* author */
	'LessWrong', /* publisher */
        'OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI|AI Safety', /* cause_area */
	'In this post, Andrew_Critch expresses his general perspective about OpenAI. He mentions reasons for his positive views of OpenAI like transparency, charter effectiveness, public engagement, etc. He thus calls for balanced critique of the organization saying that harsh criticism of OpenAI might be counterproductive for overall AI safety.' /* notes */
)
,(
	'https://www.lesswrong.com/posts/jfYnq8pKLpKLwaRGN/transcript-yudkowsky-on-
	bankless-follow-up-q-and-a', /* url */
	'Transcript: Yudkowsky on Bankless follow-up Q&A', /* title */
        '2023-02-28', /* publication_date */
	NULL, /* modified_date */
	NULL, /* author */
        'LessWrong', /* publisher */
        'OpenAI', /* affected_organizations */
        'Eliezer', /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI Safety', /* cause_area */
        'In an interview, Eliezer Yudkowsky expresses a critical view of OpenAI saying that OpenAI''s efforts in AI safety is insufficient and ineffective. He argues that their actions are setting bad examples and intensifying competition in AI development, which he sees as dangerous. If given control, Yudkowsky says he would dramatically change OpenAI''s approach. He would rename it to "ClosedAI," cut ties with Microsoft, stop generating hype, and focus on developing more alignable AI systems rather than just more powerful ones.' /* notes */
)
,(
	'https://www.lesswrong.com/posts/3S4nyoNEEuvNsbXt8/common-misconceptions-about-openai', /* url */
	'Common misconceptions about OpenAI', /* title */
	'2022-08-25', /* publication_date */
        NULL, /* modified_date */
	'Jacob_Hilton', /* author */
	'LessWrong', /* publisher */
	'OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI Safety', /* cause_area */
        'This post contains the author''s list of common misconceptions about OpenAI. He lists and explains some accurate impressions, common misconceptions and his personal views about OpenAI.' /* notes */
);
